@article{Wang2013,
abstract = {Next generation sequencing is a powerful approach for discovering genetic variation. Sensitive variant calling and haplotype inference from population sequencing data remains challenging. We describe herein, methods for high quality discovery, genotyping and phasing of SNPs for low coverage (\~{}5X) sequencing of populations, implemented in a pipeline called SNPTools. Our pipeline contains several innovations that specifically address challenges caused by low coverage population sequencing: (1) Effective Base Depth (EBD), a non-parametric statistic which enables more accurate statistical modeling of sequencing data, (2) Variance Ratio Scoring, a variance based statistic that discovers polymorphic loci with high sensitivity and specificity and, (3) BAM -specific Binomial Mixture Modeling (BBMM), a clustering algorithm which generates robust genotype likelihoods from heterogeneous sequencing data. Lastly, we develop an imputation engine that refines raw genotype likelihoods to produce high quality phased genotypes/haplotypes. Designed for large population studies, SNPTools' input/output (I/O) and storage aware design leads to improved computing performance on large sequencing datasets. We apply SNPTools to the International 1000 Genomes Project (1000G) Phase 1 low-coverage dataset and obtain genotyping accuracy comparable to that of SNP microarray.},
author = {Wang, Yi and Lu, James and Yu, Jin and Gibbs, Richard a and Yu, Fuli},
doi = {10.1101/gr.146084.112},
file = {:Users/winni/Library/Application Support/Mendeley Desktop/Downloaded/Wang et al. - 2013 - An integrative variant analysis pipeline for accurate genotypehaplotype inference in population NGS data.pdf:pdf;:Volumes/mac-3/home/Downloads/Supplemental\_Materials.pdf:pdf},
issn = {1549-5469},
journal = {Genome research},
month = jan,
pmid = {23296920},
title = {{An integrative variant analysis pipeline for accurate genotype/haplotype inference in population NGS data.}},
url = {http://www.ncbi.nlm.nih.gov/pubmed/23296920},
year = {2013}
}
@article{Lunter2011,
author = {Lunter, Gerton and Goodson, Martin},
doi = {10.1101/gr.111120.110.tions},
file = {:Users/winni/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - Unknown - No Title(10).pdf:pdf;:Users/winni/Library/Application Support/Mendeley Desktop/Downloaded/Lunter, Goodson - 2011 - Stampy A statistical algorithm for sensitive and fast mapping of Illumina sequence reads.pdf:pdf},
journal = {Genome research},
number = {3},
pages = {936--939},
title = {{Stampy: A statistical algorithm for sensitive and fast mapping of Illumina sequence reads}},
url = {http://genome.cshlp.org/content/21/6/936.short},
year = {2011}
}
@article{Trio2011,
abstract = {Recent advances in sequencing technology make it possible to comprehensively catalog genetic variation in population samples, creating a foundation for understanding human disease, ancestry and evolution. The amounts of raw data produced are prodigious, and many computational steps are required to translate this output into high-quality variant calls. We present a unified analytic framework to discover and genotype variation among multiple samples simultaneously that achieves sensitive and specific results across five sequencing technologies and three distinct, canonical experimental designs. Our process includes (i) initial read mapping; (ii) local realignment around indels; (iii) base quality score recalibration; (iv) SNP discovery and genotyping to find all potential variants; and (v) machine learning to separate true segregating variation from machine artifacts common to next-generation sequencing technologies. We here discuss the application of these tools, instantiated in the Genome Analysis Toolkit, to deep whole-genome, whole-exome capture and multi-sample low-pass (∼4×) 1000 Genomes Project datasets.},
author = {Trio, Genomes C E U and DePristo, Mark a and Banks, Eric and Poplin, Ryan and Garimella, Kiran V and Maguire, Jared R and Hartl, Christopher and Philippakis, Anthony a and del Angel, Guillermo and Rivas, Manuel a and Hanna, Matt and McKenna, Aaron and Fennell, Tim J and Kernytsky, Andrew M and Sivachenko, Andrey Y and Cibulskis, Kristian and Gabriel, Stacey B and Altshuler, David and Daly, Mark J},
doi = {10.1038/ng.806},
file = {:Users/winni/Library/Application Support/Mendeley Desktop/Downloaded/Trio - Unknown - A framework for variation discovery and genotyping using next-generation DNA sequencing data.pdf:pdf;:Users/winni/Library/Application Support/Mendeley Desktop/Downloaded/DePristo et al. - 2011 - A framework for variation discovery and genotyping using next-generation DNA sequencing data.pdf:pdf},
issn = {1546-1718},
journal = {Nature genetics},
keywords = {DNA,DNA: methods,DNA: statistics \& numerical dat,Data Interpretation,Databases,Exons,Genetic Variation,Genetics,Genome,Genotype,Human,Humans,Nucleic Acid,Polymorphism,Population,Population: methods,Population: statistics \& numerical data,Sequence Alignment,Sequence Alignment: methods,Sequence Alignment: statistics \& numerical data,Sequence Analysis,Single Nucleotide,Software,Statistical},
month = may,
number = {5},
pages = {491--8},
pmid = {21478889},
title = {{A framework for variation discovery and genotyping using next-generation DNA sequencing data.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3083463\&tool=pmcentrez\&rendertype=abstract},
volume = {43},
year = {2011}
}
@article{Pasaniuc2012,
author = {Pasaniuc, Bogdan and Rohland, Nadin and McLaren, Paul J and Garimella, Kiran and Zaitlen, Noah and Li, Heng and Gupta, Namrata and Neale, Benjamin M and Daly, Mark J and Sklar, Pamela and Sullivan, Patrick F and Bergen, Sarah and Moran, Jennifer L and Hultman, Christina M and Lichtenstein, Paul and Magnusson, Patrik and Purcell, Shaun M and Haas, David W and Liang, Liming and Sunyaev, Shamil and Patterson, Nick and de Bakker, Paul I W and Reich, David and Price, Alkes L},
doi = {10.1038/ng.2283},
file = {:Users/winni/Library/Application Support/Mendeley Desktop/Downloaded/Pasaniuc et al. - 2012 - Extremely low-coverage sequencing and imputation increases power for genome-wide association studies.pdf:pdf},
issn = {1061-4036},
journal = {Nature Genetics},
keywords = {marchini},
mendeley-tags = {marchini},
month = may,
number = {6},
pages = {631--635},
publisher = {Nature Publishing Group},
title = {{Extremely low-coverage sequencing and imputation increases power for genome-wide association studies}},
url = {http://www.nature.com/doifinder/10.1038/ng.2283},
volume = {44},
year = {2012}
}
@article{Howie2009,
abstract = {Genotype imputation methods are now being widely used in the analysis of genome-wide association studies. Most imputation analyses to date have used the HapMap as a reference dataset, but new reference panels (such as controls genotyped on multiple SNP chips and densely typed samples from the 1,000 Genomes Project) will soon allow a broader range of SNPs to be imputed with higher accuracy, thereby increasing power. We describe a genotype imputation method (IMPUTE version 2) that is designed to address the challenges presented by these new datasets. The main innovation of our approach is a flexible modelling framework that increases accuracy and combines information across multiple reference panels while remaining computationally feasible. We find that IMPUTE v2 attains higher accuracy than other methods when the HapMap provides the sole reference panel, but that the size of the panel constrains the improvements that can be made. We also find that imputation accuracy can be greatly enhanced by expanding the reference panel to contain thousands of chromosomes and that IMPUTE v2 outperforms other methods in this setting at both rare and common SNPs, with overall error rates that are 15\%-20\% lower than those of the closest competing method. One particularly challenging aspect of next-generation association studies is to integrate information across multiple reference panels genotyped on different sets of SNPs; we show that our approach to this problem has practical advantages over other suggested solutions.},
author = {Howie, Bryan N and Donnelly, Peter and Marchini, Jonathan},
doi = {10.1371/journal.pgen.1000529},
file = {:Volumes/mac-3/home/Downloads/journal.pgen.1000529.pdf:pdf},
issn = {1553-7404},
journal = {PLoS genetics},
keywords = {Genetics, Population,Genome-Wide Association Study,Genome-Wide Association Study: methods,Genotype,Humans,Polymorphism, Single Nucleotide,Software},
month = jun,
number = {6},
pages = {e1000529},
pmid = {19543373},
title = {{A flexible and accurate genotype imputation method for the next generation of genome-wide association studies.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2689936\&tool=pmcentrez\&rendertype=abstract},
volume = {5},
year = {2009}
}
@article{Li2010,
abstract = {Genome-wide association studies (GWAS) can identify common alleles that contribute to complex disease susceptibility. Despite the large number of SNPs assessed in each study, the effects of most common SNPs must be evaluated indirectly using either genotyped markers or haplotypes thereof as proxies. We have previously implemented a computationally efficient Markov Chain framework for genotype imputation and haplotyping in the freely available MaCH software package. The approach describes sampled chromosomes as mosaics of each other and uses available genotype and shotgun sequence data to estimate unobserved genotypes and haplotypes, together with useful measures of the quality of these estimates. Our approach is already widely used to facilitate comparison of results across studies as well as meta-analyses of GWAS. Here, we use simulations and experimental genotypes to evaluate its accuracy and utility, considering choices of genotyping panels, reference panel configurations, and designs where genotyping is replaced with shotgun sequencing. Importantly, we show that genotype imputation not only facilitates cross study analyses but also increases power of genetic association studies. We show that genotype imputation of common variants using HapMap haplotypes as a reference is very accurate using either genome-wide SNP data or smaller amounts of data typical in fine-mapping studies. Furthermore, we show the approach is applicable in a variety of populations. Finally, we illustrate how association analyses of unobserved variants will benefit from ongoing advances such as larger HapMap reference panels and whole genome shotgun sequencing technologies.},
author = {Li, Yun and Willer, Cristen J and Ding, Jun and Scheet, Paul and Abecasis, Gon\c{c}alo R},
doi = {10.1002/gepi.20533},
file = {:Volumes/mac-3/home/Downloads/20533\_ftp.pdf:pdf},
issn = {1098-2272},
journal = {Genetic epidemiology},
keywords = {Alleles,Base Sequence,Chromosomes,Genetic Markers,Genome, Human,Genome-Wide Association Study,Genome-Wide Association Study: methods,Genotype,Haplotypes,Humans,Markov Chains,Polymorphism, Single Nucleotide,Polymorphism, Single Nucleotide: genetics,Sensitivity and Specificity,Software},
month = dec,
number = {8},
pages = {816--34},
pmid = {21058334},
title = {{MaCH: using sequence and genotype data to estimate haplotypes and unobserved genotypes.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=3175618\&tool=pmcentrez\&rendertype=abstract},
volume = {34},
year = {2010}
}
@article{McKenna2010,
abstract = {Next-generation DNA sequencing (NGS) projects, such as the 1000 Genomes Project, are already revolutionizing our understanding of genetic variation among individuals. However, the massive data sets generated by NGS--the 1000 Genome pilot alone includes nearly five terabases--make writing feature-rich, efficient, and robust analysis tools difficult for even computationally sophisticated individuals. Indeed, many professionals are limited in the scope and the ease with which they can answer scientific questions by the complexity of accessing and manipulating the data produced by these machines. Here, we discuss our Genome Analysis Toolkit (GATK), a structured programming framework designed to ease the development of efficient and robust analysis tools for next-generation DNA sequencers using the functional programming philosophy of MapReduce. The GATK provides a small but rich set of data access patterns that encompass the majority of analysis tool needs. Separating specific analysis calculations from common data management infrastructure enables us to optimize the GATK framework for correctness, stability, and CPU and memory efficiency and to enable distributed and shared memory parallelization. We highlight the capabilities of the GATK by describing the implementation and application of robust, scale-tolerant tools like coverage calculators and single nucleotide polymorphism (SNP) calling. We conclude that the GATK programming framework enables developers and analysts to quickly and easily write efficient and robust NGS tools, many of which have already been incorporated into large-scale sequencing projects like the 1000 Genomes Project and The Cancer Genome Atlas.},
author = {McKenna, Aaron and Hanna, Matthew and Banks, Eric and Sivachenko, Andrey and Cibulskis, Kristian and Kernytsky, Andrew and Garimella, Kiran and Altshuler, David and Gabriel, Stacey and Daly, Mark and DePristo, Mark a},
doi = {10.1101/gr.107524.110},
file = {:Volumes/mac-3/home/Downloads/Genome Res.-2010-McKenna-1297-303.pdf:pdf},
issn = {1549-5469},
journal = {Genome research},
keywords = {Base Sequence,Genome,Genomics,Genomics: methods,Sequence Analysis, DNA,Sequence Analysis, DNA: methods,Software},
month = sep,
number = {9},
pages = {1297--303},
pmid = {20644199},
title = {{The Genome Analysis Toolkit: a MapReduce framework for analyzing next-generation DNA sequencing data.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2928508\&tool=pmcentrez\&rendertype=abstract},
volume = {20},
year = {2010}
}
@article{Li2009,
abstract = {The enormous amount of short reads generated by the new DNA sequencing technologies call for the development of fast and accurate read alignment programs. A first generation of hash table-based methods has been developed, including MAQ, which is accurate, feature rich and fast enough to align short reads from a single individual. However, MAQ does not support gapped alignment for single-end reads, which makes it unsuitable for alignment of longer reads where indels may occur frequently. The speed of MAQ is also a concern when the alignment is scaled up to the resequencing of hundreds of individuals.},
author = {Li, Heng and Durbin, Richard},
doi = {10.1093/bioinformatics/btp324},
file = {:Volumes/mac-3/home/Downloads/btp324.pdf:pdf},
issn = {1367-4811},
journal = {Bioinformatics (Oxford, England)},
keywords = {Algorithms,Genomics,Genomics: methods,Sequence Alignment,Sequence Alignment: methods,Sequence Analysis, DNA,Sequence Analysis, DNA: methods,Software},
month = jul,
number = {14},
pages = {1754--60},
pmid = {19451168},
title = {{Fast and accurate short read alignment with Burrows-Wheeler transform.}},
url = {http://www.pubmedcentral.nih.gov/articlerender.fcgi?artid=2705234\&tool=pmcentrez\&rendertype=abstract},
volume = {25},
year = {2009}
}
@article{Project2012,
abstract = {By characterizing the geographic and functional spectrum of human genetic variation, the 1000 Genomes Project aims to build a resource to help to understand the genetic contribution to disease. Here we describe the genomes of 1,092 individuals from 14 populations, constructed using a combination of low-coverage whole-genome and exome sequencing. By developing methods to integrate information across several algorithms and diverse data sources, we provide a validated haplotype map of 38million single nucleotide polymorphisms, 1.4million short insertions and deletions, and more than 14,000 larger deletions. We show that individuals from different populations carry different profiles of rare and common variants, and that low-frequency variants show substantial geographic differentiation, which is further increased by the action of purifying selection. We show that evolutionary conservation and coding consequence are key determinants of the strength of purifying selection, that rare-variant load varies substantially across biological pathways, and that each individual contains hundreds of rare non-coding variants at conserved sites, such as motif-disrupting changes in transcription-factor-binding sites. This resource, which captures up to 98\% of accessible single nucleotide polymorphisms at a frequency of 1\% in related populations, enables analysis of common and low-frequency variants in individuals from diverse, including admixed, populations.},
author = {Consortium, Genomes Project and Abecasis, Goncalo R and Auton, Adam and Brooks, Lisa D and DePristo, Mark A and Durbin, Richard M and Handsaker, Robert E and Kang, Hyun Min and Marth, Gabor T and McVean, Gil A},
doi = {10.1038/nature11632},
file = {:Users/winni/Library/Application Support/Mendeley Desktop/Downloaded/Unknown - 2012 - An integrated map of genetic variation from 1,092 human genomes.pdf:pdf;:Users/winni/Library/Application Support/Mendeley Desktop/Downloaded/Project et al. - 2012 - An integrated map of genetic variation from 1,092 human genomes.pdf:pdf},
issn = {00280836},
journal = {Nature},
number = {V},
pages = {1--113},
publisher = {Nature Publishing Group},
title = {{An integrated map of genetic variation from 1,092 human genomes}},
url = {http://www.nature.com/nature/journal/v491/n7422/full/nature11632.html http://eutils.ncbi.nlm.nih.gov/entrez/eutils/elink.fcgi?dbfrom=pubmed\&id=23128226\&retmode=ref\&cmd=prlinks},
volume = {135},
year = {2012}
}
